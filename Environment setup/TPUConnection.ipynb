{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TPUConnection.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "29rDqRvIYWK-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Testing out the TPU connection\n",
        "**First, you'll need to enable TPUs for the notebook.**\n",
        "\n",
        "Navigate to Editâ†’Notebook Settings, and select TPU from the Hardware Accelerator drop-down (you can also access Notebook Settings via the command palette: cmd/ctrl-shift-P).\n",
        "\n",
        "Next, we'll check that we can connect to the TPU."
      ]
    },
    {
      "metadata": {
        "id": "Tu43FA5KYZa2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "12fb0e1e-f52c-46a8-beab-a9ff1e440ed0"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pprint\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "if \"COLAB_TPU_ADDR\" not in os.environ:\n",
        "  print(\"ERROR:Not connected\")\n",
        "else:\n",
        "  tpu_add=\"grpc://\" + os.environ[\"COLAB_TPU_ADDR\"]\n",
        "  print(tpu_add)\n",
        "  \n",
        "  with tf.Session(tpu_add) as sess:\n",
        "    device=sess.list_devices()\n",
        "    \n",
        "  pprint.pprint(device)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "grpc://10.123.35.58:8470\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 13926691758422460206),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 17874054952487983121),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 2624001016290872265),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 1687921026759612548),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 2046865625999329659),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 11151955258944101478),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 16621828166326490096),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 9470243095569248129),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 4509716768415436743),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 11760775855562173219),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 749492492091025471)]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}