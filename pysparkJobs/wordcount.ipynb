{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "Nr2Dnt-XoQ6D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Spark WordCount"
      ]
    },
    {
      "metadata": {
        "id": "XXegKD32oPqA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "4714d1ac-bbd0-463e-cde8-27006a220d46"
      },
      "cell_type": "code",
      "source": [
        "!pip3 install pyspark"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/64/a1df4440483df47381bbbf6a03119ef66515cf2e1a766d9369811575454b/pyspark-2.4.1.tar.gz (215.7MB)\n",
            "\u001b[K    100% |████████████████████████████████| 215.7MB 114kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7 (from pyspark)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K    100% |████████████████████████████████| 204kB 27.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/47/9b/57/7984bf19763749a13eece44c3174adb6ae4bc95b920375ff50\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kq-ArR0AoYhL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from pyspark import SparkContext,SparkConf\n",
        "\n",
        "conf=SparkConf().setAppName(\"WordCount\").setMaster(\"local\")\n",
        "sc=SparkContext(conf=conf)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H8o-fbA7o811",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lines = sc.textFile(\"sample_data/README.md\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WgT-mbNxpUw2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1109
        },
        "outputId": "f8820cca-095b-4dc6-b405-3f9477a31bb4"
      },
      "cell_type": "code",
      "source": [
        "words=lines.flatMap(lambda line: line.split(\" \"))\n",
        "wordcounts=words.countByValue()\n",
        "\n",
        "\n",
        "for word,count in wordcounts.items():\n",
        "  print(\"{}:{}\".format(word,count))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This:1\n",
            "directory:1\n",
            "includes:1\n",
            "a:3\n",
            "few:1\n",
            "sample:2\n",
            "datasets:1\n",
            "to:1\n",
            "get:1\n",
            "you:1\n",
            "started.:1\n",
            ":24\n",
            "*:3\n",
            "`california_housing_data*.csv`:1\n",
            "is:4\n",
            "California:1\n",
            "housing:1\n",
            "data:1\n",
            "from:1\n",
            "the:3\n",
            "1990:1\n",
            "US:1\n",
            "Census;:1\n",
            "more:1\n",
            "information:1\n",
            "available:1\n",
            "at::2\n",
            "https://developers.google.com/machine-learning/crash-course/california-housing-data-description:1\n",
            "`mnist_*.csv`:1\n",
            "small:1\n",
            "of:2\n",
            "[MNIST:1\n",
            "database](https://en.wikipedia.org/wiki/MNIST_database),:1\n",
            "which:1\n",
            "described:2\n",
            "http://yann.lecun.com/exdb/mnist/:1\n",
            "`anscombe.json`:1\n",
            "contains:1\n",
            "copy:2\n",
            "[Anscombe's:1\n",
            "quartet](https://en.wikipedia.org/wiki/Anscombe%27s_quartet);:1\n",
            "it:1\n",
            "was:2\n",
            "originally:1\n",
            "in:2\n",
            "Anscombe,:1\n",
            "F.:1\n",
            "J.:1\n",
            "(1973).:1\n",
            "'Graphs:1\n",
            "Statistical:1\n",
            "Analysis'.:1\n",
            "American:1\n",
            "Statistician.:1\n",
            "27:1\n",
            "(1)::1\n",
            "17-21.:1\n",
            "JSTOR:1\n",
            "2682899.:1\n",
            "and:1\n",
            "our:1\n",
            "prepared:1\n",
            "by:1\n",
            "[vega_datasets:1\n",
            "library](https://github.com/altair-viz/vega_datasets/blob/4f67bdaad10f45e3549984e17e1b3088c731503d/vega_datasets/_data/anscombe.json).:1\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}