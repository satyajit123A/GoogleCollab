{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RDD_BASIC.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "XSKfuZ574Azp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Create entry points to spark\n"
      ]
    },
    {
      "metadata": {
        "id": "lfOLIROL4QR4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "52708629-4ce9-4d2c-dd2e-796df03dc4f8"
      },
      "cell_type": "code",
      "source": [
        "!pip3 install pyspark"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/64/a1df4440483df47381bbbf6a03119ef66515cf2e1a766d9369811575454b/pyspark-2.4.1.tar.gz (215.7MB)\n",
            "\u001b[K    100% |████████████████████████████████| 215.7MB 115kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7 (from pyspark)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K    100% |████████████████████████████████| 204kB 29.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/47/9b/57/7984bf19763749a13eece44c3174adb6ae4bc95b920375ff50\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NkZy1lgc37j6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "try:\n",
        "  sc.stop()\n",
        "except:\n",
        "  pass\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SparkSession\n",
        "sc=SparkContext()\n",
        "spark=SparkSession(sparkContext=sc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yOyJHTaY5L8_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RDD object\n",
        "The class **pyspark.SparkContext** creates a client which connects to a Spark cluster. This client can be used to create an RDD object. There are two methods from this class for directly creating RDD objects:\n",
        "\n",
        "\n",
        "\n",
        "*   parallelize()\n",
        "*   textFile()\n",
        "\n",
        "\n",
        "# parallelize()\n",
        "parallelize() distribute a **local python collection** to form an RDD. Common built-in python collections include dist, list, tuple or set.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "fiuvWOAo5Lr_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c5f48144-9f35-49ea-bf1c-75cde3e9931e"
      },
      "cell_type": "code",
      "source": [
        "rdd=sc.parallelize([1,2,3])\n",
        "rdd.collect()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "h_Hdgi6z466g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "017f19e6-4512-4484-f160-aad1587bcda4"
      },
      "cell_type": "code",
      "source": [
        "# from a list of tuple\n",
        "list_t = [('cat', 'dog', 'fish'), ('orange', 'apple')]\n",
        "rdd = sc.parallelize(list_t)\n",
        "rdd.collect()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('cat', 'dog', 'fish'), ('orange', 'apple')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "1ihUSYCj56zm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "90e857d7-0190-44f8-fe86-b2575fc30b61"
      },
      "cell_type": "code",
      "source": [
        "# from a set\n",
        "s = {'cat', 'dog', 'fish', 'cat', 'dog', 'dog'}\n",
        "rdd = sc.parallelize(s)\n",
        "rdd.collect()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['fish', 'cat', 'dog']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "8TBt1ReU57-L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f814c6c-e493-4eeb-c01a-62fe1573f1fd"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# from a dict\n",
        "d = {\n",
        "    'a': 100,\n",
        "    'b': 200,\n",
        "    'c': 300\n",
        "}\n",
        "rdd = sc.parallelize(d)\n",
        "rdd.collect()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a', 'b', 'c']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "YT-cWG6k6GVe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# textFile()\n",
        "\n",
        "The textFile() function reads a text file and returns it as an RDD of strings. Usually, you will need to apply some map functions to transform each elements of the RDD to some data structure/type that is suitable for data analysis.\n",
        "\n",
        "**When using textFile(), each line of the text file becomes an element in the resulting RDD.**\n"
      ]
    },
    {
      "metadata": {
        "id": "PX8-GHrY6aMZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "43f22104-607c-4a89-dd4f-824440d55415"
      },
      "cell_type": "code",
      "source": [
        "rddh=sc.textFile(\"sample_data/california_housing_train.csv\")\n",
        "rddh.take(5)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\"longitude\",\"latitude\",\"housing_median_age\",\"total_rooms\",\"total_bedrooms\",\"population\",\"households\",\"median_income\",\"median_house_value\"',\n",
              " '-114.310000,34.190000,15.000000,5612.000000,1283.000000,1015.000000,472.000000,1.493600,66900.000000',\n",
              " '-114.470000,34.400000,19.000000,7650.000000,1901.000000,1129.000000,463.000000,1.820000,80100.000000',\n",
              " '-114.560000,33.690000,17.000000,720.000000,174.000000,333.000000,117.000000,1.650900,85700.000000',\n",
              " '-114.570000,33.640000,14.000000,1501.000000,337.000000,515.000000,226.000000,3.191700,73400.000000']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "59kx25H768q-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "# DataFrame object\n",
        "# Creat DataFrame by reading a file"
      ]
    },
    {
      "metadata": {
        "id": "4mgJaU8D7Dro",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "452f54c2-dceb-4748-df4f-b70006325571"
      },
      "cell_type": "code",
      "source": [
        "houseing_data=spark.read.csv(path=\"sample_data/california_housing_train.csv\",sep=\",\",encoding=\"UTF-8\",comment=None,header=True,inferSchema=True)\n",
        "houseing_data.show(5,truncate=False)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|-114.31  |34.19   |15.0              |5612.0     |1283.0        |1015.0    |472.0     |1.4936       |66900.0           |\n",
            "|-114.47  |34.4    |19.0              |7650.0     |1901.0        |1129.0    |463.0     |1.82         |80100.0           |\n",
            "|-114.56  |33.69   |17.0              |720.0      |174.0         |333.0     |117.0     |1.6509       |85700.0           |\n",
            "|-114.57  |33.64   |14.0              |1501.0     |337.0         |515.0     |226.0     |3.1917       |73400.0           |\n",
            "|-114.57  |33.57   |20.0              |1454.0     |326.0         |624.0     |262.0     |1.925        |65500.0           |\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HqQMsXdB_JVZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Create DataFrame with createDataFrame function\n",
        "\n",
        "# From an RDD\n",
        "\n",
        "Elements in RDD has to be an Row object"
      ]
    },
    {
      "metadata": {
        "id": "p9RVoMDO7yJR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7b14f294-0b43-4c1c-dedd-3671e8dd2898"
      },
      "cell_type": "code",
      "source": [
        "from pyspark.sql import Row\n",
        "rdd=sc.parallelize([Row(x=[1,2,3],y=[\"a\",\"b\",\"c\"]),Row(x=[4,5,6],y=[\"g\",\"h\",\"i\"])])\n",
        "rdd.collect()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(x=[1, 2, 3], y=['a', 'b', 'c']), Row(x=[4, 5, 6], y=['g', 'h', 'i'])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "pVSleC--_4AX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "cd9518a7-091d-48e0-9709-a34361986288"
      },
      "cell_type": "code",
      "source": [
        "df=spark.createDataFrame(rdd)\n",
        "df.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+---------+\n",
            "|        x|        y|\n",
            "+---------+---------+\n",
            "|[1, 2, 3]|[a, b, c]|\n",
            "|[4, 5, 6]|[g, h, i]|\n",
            "+---------+---------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z4hXfICAAGZZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# From pandas DataFrame\n"
      ]
    },
    {
      "metadata": {
        "id": "jxHHMXMq__FH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "64e714d2-f99b-49a7-a863-d220afbdd356"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "house=pd.read_csv(\"sample_data/california_housing_train.csv\")\n",
        "house.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-114.31</td>\n",
              "      <td>34.19</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5612.0</td>\n",
              "      <td>1283.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>472.0</td>\n",
              "      <td>1.4936</td>\n",
              "      <td>66900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-114.47</td>\n",
              "      <td>34.40</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7650.0</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>1.8200</td>\n",
              "      <td>80100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-114.56</td>\n",
              "      <td>33.69</td>\n",
              "      <td>17.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>1.6509</td>\n",
              "      <td>85700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.64</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1501.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>3.1917</td>\n",
              "      <td>73400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.57</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1454.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>624.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1.9250</td>\n",
              "      <td>65500.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0    -114.31     34.19                15.0       5612.0          1283.0   \n",
              "1    -114.47     34.40                19.0       7650.0          1901.0   \n",
              "2    -114.56     33.69                17.0        720.0           174.0   \n",
              "3    -114.57     33.64                14.0       1501.0           337.0   \n",
              "4    -114.57     33.57                20.0       1454.0           326.0   \n",
              "\n",
              "   population  households  median_income  median_house_value  \n",
              "0      1015.0       472.0         1.4936             66900.0  \n",
              "1      1129.0       463.0         1.8200             80100.0  \n",
              "2       333.0       117.0         1.6509             85700.0  \n",
              "3       515.0       226.0         3.1917             73400.0  \n",
              "4       624.0       262.0         1.9250             65500.0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "wbnkY-I1ArAQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "56c03419-ad26-4ac8-ffab-836a4d20c6cf"
      },
      "cell_type": "code",
      "source": [
        "house_spark=spark.createDataFrame(house)\n",
        "house_spark.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|  -114.31|   34.19|              15.0|     5612.0|        1283.0|    1015.0|     472.0|       1.4936|           66900.0|\n",
            "|  -114.47|    34.4|              19.0|     7650.0|        1901.0|    1129.0|     463.0|         1.82|           80100.0|\n",
            "|  -114.56|   33.69|              17.0|      720.0|         174.0|     333.0|     117.0|       1.6509|           85700.0|\n",
            "|  -114.57|   33.64|              14.0|     1501.0|         337.0|     515.0|     226.0|       3.1917|           73400.0|\n",
            "|  -114.57|   33.57|              20.0|     1454.0|         326.0|     624.0|     262.0|        1.925|           65500.0|\n",
            "|  -114.58|   33.63|              29.0|     1387.0|         236.0|     671.0|     239.0|       3.3438|           74000.0|\n",
            "|  -114.58|   33.61|              25.0|     2907.0|         680.0|    1841.0|     633.0|       2.6768|           82400.0|\n",
            "|  -114.59|   34.83|              41.0|      812.0|         168.0|     375.0|     158.0|       1.7083|           48500.0|\n",
            "|  -114.59|   33.61|              34.0|     4789.0|        1175.0|    3134.0|    1056.0|       2.1782|           58400.0|\n",
            "|   -114.6|   34.83|              46.0|     1497.0|         309.0|     787.0|     271.0|       2.1908|           48100.0|\n",
            "|   -114.6|   33.62|              16.0|     3741.0|         801.0|    2434.0|     824.0|       2.6797|           86500.0|\n",
            "|   -114.6|    33.6|              21.0|     1988.0|         483.0|    1182.0|     437.0|        1.625|           62000.0|\n",
            "|  -114.61|   34.84|              48.0|     1291.0|         248.0|     580.0|     211.0|       2.1571|           48600.0|\n",
            "|  -114.61|   34.83|              31.0|     2478.0|         464.0|    1346.0|     479.0|        3.212|           70400.0|\n",
            "|  -114.63|   32.76|              15.0|     1448.0|         378.0|     949.0|     300.0|       0.8585|           45000.0|\n",
            "|  -114.65|   34.89|              17.0|     2556.0|         587.0|    1005.0|     401.0|       1.6991|           69100.0|\n",
            "|  -114.65|    33.6|              28.0|     1678.0|         322.0|     666.0|     256.0|       2.9653|           94900.0|\n",
            "|  -114.65|   32.79|              21.0|       44.0|          33.0|      64.0|      27.0|       0.8571|           25000.0|\n",
            "|  -114.66|   32.74|              17.0|     1388.0|         386.0|     775.0|     320.0|       1.2049|           44000.0|\n",
            "|  -114.67|   33.92|              17.0|       97.0|          24.0|      29.0|      15.0|       1.2656|           27500.0|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "16MdXgNZBEDQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Column instance\n",
        "\n",
        "Column instances can be created in two ways:\n",
        "\n",
        "\n",
        "\n",
        "*   directly select a column out of a DataFrame: **df.colName**\n",
        "*   create from a column expression: **df.colName + 1**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Remember how to create column instances, because this is usually the starting point if we want to operate DataFrame columns.**\n",
        "\n",
        "The column classes come with some methods that can operate on a column instance. However, almost all functions from ***the pyspark.sql.functions*** module take one or more column instances as argument(s). These functions are important for data manipulation tools.\n",
        "\n",
        "\n",
        "\n",
        "# DataFrame column methods\n",
        "\n",
        "\n",
        "# Methods that take column names as arguments:\n",
        "\n",
        "\n",
        "*   corr(col1, col2): two column names\n",
        "*   cov(col1, col2): two column names.\n",
        "\n",
        "*   describe(*cols): `cols` refers to only column names (strings).*\n",
        "\n",
        "*   crosstab(col1, col2): two column names.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Methods that take column names or column expressions or both as arguments:\n",
        "\n",
        "\n",
        "\n",
        "*  cube(*cols): column names (string) or column expressions or both.\n",
        "*   drop(*cols): a list of column names OR a single column expression.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   groupBy(*cols): column name (string) or column expression or both.\n",
        "*  rollup(*cols): column name (string) or column expression or both.\n",
        "\n",
        "\n",
        "\n",
        "*  toDF(*cols): a list of column names (string).\n",
        "*   filter(condition): *condition refers to a column expression that returns types.BooleanType of values.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Zow6z57wEv_d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# DataFrame to RDD\n",
        "A DataFrame can be easily converted to an RDD by calling the pyspark.sql.DataFrame.rdd() function. Each element in the returned RDD is an **pyspark.sql.Row object**. An Row is a list of key-value pairs.\n"
      ]
    },
    {
      "metadata": {
        "id": "uTYAm4exAzvJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "376e731d-a529-4dc8-f5b2-2c99edca1dc1"
      },
      "cell_type": "code",
      "source": [
        "house_spark.rdd.take(2)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(longitude=-114.31, latitude=34.19, housing_median_age=15.0, total_rooms=5612.0, total_bedrooms=1283.0, population=1015.0, households=472.0, median_income=1.4936, median_house_value=66900.0),\n",
              " Row(longitude=-114.47, latitude=34.4, housing_median_age=19.0, total_rooms=7650.0, total_bedrooms=1901.0, population=1129.0, households=463.0, median_income=1.82, median_house_value=80100.0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "cAwDqbvjFE1T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "With an RDD object, we can apply a set of mapping functions, such as **map, mapValues, flatMap, flatMapValues** and a lot of other methods that come from RDD."
      ]
    },
    {
      "metadata": {
        "id": "Z4NMMGevE-1n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "96d4f7b7-04d9-48f3-b133-827569158b01"
      },
      "cell_type": "code",
      "source": [
        "house_spark_map=house_spark.rdd.map(lambda x: (x[\"longitude\"],x[\"latitude\"]))\n",
        "house_spark_map.take(5)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(-114.31, 34.19),\n",
              " (-114.47, 34.4),\n",
              " (-114.56, 33.69),\n",
              " (-114.57, 33.64),\n",
              " (-114.57, 33.57)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "wL2ZVV5SJ8xx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "6cb2c3e5-ed14-43db-f2fb-634bfea39909"
      },
      "cell_type": "code",
      "source": [
        "house_spark_mapvalues=house_spark_map.mapValues(lambda x:[x,x*10])\n",
        "house_spark_mapvalues.take(5)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(-114.31, [34.19, 341.9]),\n",
              " (-114.47, [34.4, 344.0]),\n",
              " (-114.56, [33.69, 336.9]),\n",
              " (-114.57, [33.64, 336.4]),\n",
              " (-114.57, [33.57, 335.7])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "ti-L7qsrLceO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RDD to DataFrame\n",
        "To convert an RDD to a DataFrame, we can use the SparkSession.createDataFrame() function. Every element in the RDD has be to an Row object.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "tPEqM0X2JgFo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "c78801bc-36f3-4ca8-dbe8-3dd6d31fb761"
      },
      "cell_type": "code",
      "source": [
        "raw_rdd=house_spark.rdd\n",
        "raw_rdd.take(5)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(longitude=-114.31, latitude=34.19, housing_median_age=15.0, total_rooms=5612.0, total_bedrooms=1283.0, population=1015.0, households=472.0, median_income=1.4936, median_house_value=66900.0),\n",
              " Row(longitude=-114.47, latitude=34.4, housing_median_age=19.0, total_rooms=7650.0, total_bedrooms=1901.0, population=1129.0, households=463.0, median_income=1.82, median_house_value=80100.0),\n",
              " Row(longitude=-114.56, latitude=33.69, housing_median_age=17.0, total_rooms=720.0, total_bedrooms=174.0, population=333.0, households=117.0, median_income=1.6509, median_house_value=85700.0),\n",
              " Row(longitude=-114.57, latitude=33.64, housing_median_age=14.0, total_rooms=1501.0, total_bedrooms=337.0, population=515.0, households=226.0, median_income=3.1917, median_house_value=73400.0),\n",
              " Row(longitude=-114.57, latitude=33.57, housing_median_age=20.0, total_rooms=1454.0, total_bedrooms=326.0, population=624.0, households=262.0, median_income=1.925, median_house_value=65500.0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "QoDRTzz4LsAA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "6c558d66-5dd0-41e9-8043-34af77082000"
      },
      "cell_type": "code",
      "source": [
        "rddh.take(5)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\"longitude\",\"latitude\",\"housing_median_age\",\"total_rooms\",\"total_bedrooms\",\"population\",\"households\",\"median_income\",\"median_house_value\"',\n",
              " '-114.310000,34.190000,15.000000,5612.000000,1283.000000,1015.000000,472.000000,1.493600,66900.000000',\n",
              " '-114.470000,34.400000,19.000000,7650.000000,1901.000000,1129.000000,463.000000,1.820000,80100.000000',\n",
              " '-114.560000,33.690000,17.000000,720.000000,174.000000,333.000000,117.000000,1.650900,85700.000000',\n",
              " '-114.570000,33.640000,14.000000,1501.000000,337.000000,515.000000,226.000000,3.191700,73400.000000']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "id": "Go5tM73HOUJz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "03a1055c-9d95-47f0-e230-1dfa737aaec1"
      },
      "cell_type": "code",
      "source": [
        "header=rddh.map(lambda x:x.split(\",\")).collect()[0]\n",
        "header"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\"longitude\"',\n",
              " '\"latitude\"',\n",
              " '\"housing_median_age\"',\n",
              " '\"total_rooms\"',\n",
              " '\"total_bedrooms\"',\n",
              " '\"population\"',\n",
              " '\"households\"',\n",
              " '\"median_income\"',\n",
              " '\"median_house_value\"']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "K5ucLgIaPAw7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "2c8a141e-b446-4dc2-b6c5-71121d9a76f6"
      },
      "cell_type": "code",
      "source": [
        "rdd = rddh.map(lambda x: x.split(',')).filter(lambda line: line != header)\n",
        "rdd.take(2)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['-114.310000',\n",
              "  '34.190000',\n",
              "  '15.000000',\n",
              "  '5612.000000',\n",
              "  '1283.000000',\n",
              "  '1015.000000',\n",
              "  '472.000000',\n",
              "  '1.493600',\n",
              "  '66900.000000'],\n",
              " ['-114.470000',\n",
              "  '34.400000',\n",
              "  '19.000000',\n",
              "  '7650.000000',\n",
              "  '1901.000000',\n",
              "  '1129.000000',\n",
              "  '463.000000',\n",
              "  '1.820000',\n",
              "  '80100.000000']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "metadata": {
        "id": "AuRKNK4cRTLo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Convert RDD elements to RDD Row objects\n",
        "First we define a function which takes a list of column names and a list of values and create a Row of key-value pairs. Since keys in an Row object are variable names, we can’t simply pass a dictionary to the Row() function. We can think of a dictionary as an argument list and use the ** to unpack the argument list."
      ]
    },
    {
      "metadata": {
        "id": "iEcMbbKTPbkm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cbaf4de1-b8fe-4fde-bf71-b880d80c0ca4"
      },
      "cell_type": "code",
      "source": [
        "from pyspark.sql import Row\n",
        "my_dict = dict(zip(['a', 'b', 'c'], range(1, 4)))\n",
        "Row(**my_dict)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(a=1, b=2, c=3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "metadata": {
        "id": "ADc2gzvsRuhG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def list_to_row(keys, values):\n",
        "    row_dict = dict(zip(keys, values))\n",
        "    return Row(**row_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wxgaToOCRy4K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "e0a826f5-d9c2-4860-d96d-57c3d077ad45"
      },
      "cell_type": "code",
      "source": [
        "rdd_rows = rdd.map(lambda x: list_to_row(header, x))\n",
        "rdd_rows.take(3)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(\"households\"='472.000000', \"housing_median_age\"='15.000000', \"latitude\"='34.190000', \"longitude\"='-114.310000', \"median_house_value\"='66900.000000', \"median_income\"='1.493600', \"population\"='1015.000000', \"total_bedrooms\"='1283.000000', \"total_rooms\"='5612.000000'),\n",
              " Row(\"households\"='463.000000', \"housing_median_age\"='19.000000', \"latitude\"='34.400000', \"longitude\"='-114.470000', \"median_house_value\"='80100.000000', \"median_income\"='1.820000', \"population\"='1129.000000', \"total_bedrooms\"='1901.000000', \"total_rooms\"='7650.000000'),\n",
              " Row(\"households\"='117.000000', \"housing_median_age\"='17.000000', \"latitude\"='33.690000', \"longitude\"='-114.560000', \"median_house_value\"='85700.000000', \"median_income\"='1.650900', \"population\"='333.000000', \"total_bedrooms\"='174.000000', \"total_rooms\"='720.000000')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "metadata": {
        "id": "sQ1IFDgyR2H3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "7a185fe2-ceb3-46fe-da4a-fbc23439203c"
      },
      "cell_type": "code",
      "source": [
        "df1 = spark.createDataFrame(rdd_rows)\n",
        "df1.show(5)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------+--------------------+----------+-----------+--------------------+---------------+------------+----------------+-------------+\n",
            "|\"households\"|\"housing_median_age\"|\"latitude\"|\"longitude\"|\"median_house_value\"|\"median_income\"|\"population\"|\"total_bedrooms\"|\"total_rooms\"|\n",
            "+------------+--------------------+----------+-----------+--------------------+---------------+------------+----------------+-------------+\n",
            "|  472.000000|           15.000000| 34.190000|-114.310000|        66900.000000|       1.493600| 1015.000000|     1283.000000|  5612.000000|\n",
            "|  463.000000|           19.000000| 34.400000|-114.470000|        80100.000000|       1.820000| 1129.000000|     1901.000000|  7650.000000|\n",
            "|  117.000000|           17.000000| 33.690000|-114.560000|        85700.000000|       1.650900|  333.000000|      174.000000|   720.000000|\n",
            "|  226.000000|           14.000000| 33.640000|-114.570000|        73400.000000|       3.191700|  515.000000|      337.000000|  1501.000000|\n",
            "|  262.000000|           20.000000| 33.570000|-114.570000|        65500.000000|       1.925000|  624.000000|      326.000000|  1454.000000|\n",
            "+------------+--------------------+----------+-----------+--------------------+---------------+------------+----------------+-------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "znlaTI4_SB4X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# merge-and-split-columns\n",
        "\n",
        "# Merge and split columns\n",
        "Sometimes we need to merge multiple columns in a Dataframe into one column, or split a column into multiple columns. We can easily achieve this by converting a DataFrame to RDD, applying map functions to manipulate elements, and then converting the RDD back to a DataFrame."
      ]
    },
    {
      "metadata": {
        "id": "bhT6BzaQSJTz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "47a59f69-bffc-4a71-e50c-8b15bebddc00"
      },
      "cell_type": "code",
      "source": [
        "colnames = df1.columns\n",
        "colnames[0] = 'households_number'\n",
        "household=df1.rdd.toDF(colnames)\n",
        "household.show(5)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------+--------------------+----------+-----------+--------------------+---------------+------------+----------------+-------------+\n",
            "|households_number|\"housing_median_age\"|\"latitude\"|\"longitude\"|\"median_house_value\"|\"median_income\"|\"population\"|\"total_bedrooms\"|\"total_rooms\"|\n",
            "+-----------------+--------------------+----------+-----------+--------------------+---------------+------------+----------------+-------------+\n",
            "|       472.000000|           15.000000| 34.190000|-114.310000|        66900.000000|       1.493600| 1015.000000|     1283.000000|  5612.000000|\n",
            "|       463.000000|           19.000000| 34.400000|-114.470000|        80100.000000|       1.820000| 1129.000000|     1901.000000|  7650.000000|\n",
            "|       117.000000|           17.000000| 33.690000|-114.560000|        85700.000000|       1.650900|  333.000000|      174.000000|   720.000000|\n",
            "|       226.000000|           14.000000| 33.640000|-114.570000|        73400.000000|       3.191700|  515.000000|      337.000000|  1501.000000|\n",
            "|       262.000000|           20.000000| 33.570000|-114.570000|        65500.000000|       1.925000|  624.000000|      326.000000|  1454.000000|\n",
            "+-----------------+--------------------+----------+-----------+--------------------+---------------+------------+----------------+-------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hb7nug2WVrV8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "52d6801e-b4d7-4db5-9a63-09c36c46f6ff"
      },
      "cell_type": "code",
      "source": [
        "from pyspark.sql import Row\n",
        "value_rdd = df1.rdd.map(lambda x: Row(model=x[0], values=x[1:]))\n",
        "value_rdd.take(5)\n",
        "value_df = spark.createDataFrame(value_rdd)\n",
        "value_df.show(5, truncate=False)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+--------------------------------------------------------------------------------------------------+\n",
            "|model     |values                                                                                            |\n",
            "+----------+--------------------------------------------------------------------------------------------------+\n",
            "|472.000000|[15.000000, 34.190000, -114.310000, 66900.000000, 1.493600, 1015.000000, 1283.000000, 5612.000000]|\n",
            "|463.000000|[19.000000, 34.400000, -114.470000, 80100.000000, 1.820000, 1129.000000, 1901.000000, 7650.000000]|\n",
            "|117.000000|[17.000000, 33.690000, -114.560000, 85700.000000, 1.650900, 333.000000, 174.000000, 720.000000]   |\n",
            "|226.000000|[14.000000, 33.640000, -114.570000, 73400.000000, 3.191700, 515.000000, 337.000000, 1501.000000]  |\n",
            "|262.000000|[20.000000, 33.570000, -114.570000, 65500.000000, 1.925000, 624.000000, 326.000000, 1454.000000]  |\n",
            "+----------+--------------------------------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_M2tabmZWfLL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Split one column\n",
        "We use the above DataFrame as our example data. Again, we need to convert the DataFrame to an RDD to achieve our goal.\n",
        "\n",
        "Let's split the values column into two columns: x1 and x2. The first 4 values will be in column x1 and the remaining values will be in column x2."
      ]
    },
    {
      "metadata": {
        "id": "O0pE-f26Wa1N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "cffe3293-000a-442d-b874-1d5a5695410a"
      },
      "cell_type": "code",
      "source": [
        "value_rdd_2 = value_df.rdd.map(lambda x: Row(model=x[0], x1=x[1][:5], x2=x[1][5:]))\n",
        "# convert RDD back to DataFrame\n",
        "value_df_2 = spark.createDataFrame(value_rdd_2)\n",
        "value_df_2.show(5, truncate=False)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-----------------------------------------------------------+---------------------------------------+\n",
            "|model     |x1                                                         |x2                                     |\n",
            "+----------+-----------------------------------------------------------+---------------------------------------+\n",
            "|472.000000|[15.000000, 34.190000, -114.310000, 66900.000000, 1.493600]|[1015.000000, 1283.000000, 5612.000000]|\n",
            "|463.000000|[19.000000, 34.400000, -114.470000, 80100.000000, 1.820000]|[1129.000000, 1901.000000, 7650.000000]|\n",
            "|117.000000|[17.000000, 33.690000, -114.560000, 85700.000000, 1.650900]|[333.000000, 174.000000, 720.000000]   |\n",
            "|226.000000|[14.000000, 33.640000, -114.570000, 73400.000000, 3.191700]|[515.000000, 337.000000, 1501.000000]  |\n",
            "|262.000000|[20.000000, 33.570000, -114.570000, 65500.000000, 1.925000]|[624.000000, 326.000000, 1454.000000]  |\n",
            "+----------+-----------------------------------------------------------+---------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}